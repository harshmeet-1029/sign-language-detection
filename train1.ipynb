{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/imdasrj98/Sign-Language-Detection-and-Conversion-to-Text-Using-CNN-and-OpenCV/blob/master/train1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 79
    },
    "colab_type": "code",
    "id": "w05J9kV5d3Ir",
    "outputId": "0acbf6f5-1389-493b-9ac3-32926b821936"
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from PIL import Image\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jlz_CAI1fPO_"
   },
   "outputs": [],
   "source": [
    "paths=['asl_dataset']\n",
    "\n",
    "x_train = [] \n",
    "y_train = []\n",
    "nb_classes = 36 \n",
    "img_rows, img_cols = 400, 400  \n",
    "img_channels = 3  \n",
    "batch_size = 32\n",
    "nb_epoch = 15 \n",
    "data_augmentation = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EeQowr-OjA8K"
   },
   "outputs": [],
   "source": [
    "classes = {\n",
    "    '0': 0,\n",
    "    '1': 1,\n",
    "    '2': 2,\n",
    "    '3': 3,\n",
    "    '4': 4,\n",
    "    '5': 5,\n",
    "    '6': 6,\n",
    "    '7': 7,\n",
    "    '8': 8,\n",
    "    '9': 9,\n",
    "    'A': 10,\n",
    "    'B': 11,\n",
    "    'C': 12,\n",
    "    'D': 13,\n",
    "    'E': 14,\n",
    "    'F': 15,\n",
    "    'G': 16,\n",
    "    'H': 17,\n",
    "    'I': 18,\n",
    "    'J': 19,\n",
    "    'K': 20,\n",
    "    'L': 21,\n",
    "    'M': 22,\n",
    "    'N': 23,\n",
    "    'O': 24,\n",
    "    'P': 25,\n",
    "    'Q': 26,\n",
    "    'R': 27,\n",
    "    'S': 28,\n",
    "    'T': 29,\n",
    "    'U': 30,\n",
    "    'V': 31,\n",
    "    'W': 32,\n",
    "    'X': 33,\n",
    "    'Y': 34,\n",
    "    'Z': 35,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gSIOd03xjGu0"
   },
   "outputs": [],
   "source": [
    "def load_data_set():\n",
    "    for path in paths:\n",
    "        print(path)\n",
    "        for root, directories, filenames in os.walk(path):\n",
    "            print(filenames)\n",
    "            for filename in filenames:\n",
    "                if filename.endswith(\".jpeg\"):\n",
    "                    fullpath = os.path.join(root, filename)\n",
    "                    img = load_img(fullpath)\n",
    "                    img = img_to_array(img)\n",
    "                    x_train.append(img)\n",
    "                    ind=fullpath.rindex('/')\n",
    "                    s=fullpath[ind-1]\n",
    "                    y_train.append(classes[s.upper()])\n",
    "    print(\"data set loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GYLPgrwVjT8k"
   },
   "outputs": [],
   "source": [
    "def make_network(x_train):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Convolution2D(32, 3, 3, border_mode='same',\n",
    "                            input_shape=x_train.shape[1:]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(32, 3, 3))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Convolution2D(64, 3, 3, border_mode='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(64, 3, 3))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(nb_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    print(\"Network Made\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fpLAl7yotTp1"
   },
   "outputs": [],
   "source": [
    "def train_model(model, X_train, Y_train):\n",
    "    sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=sgd,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.fit(X_train, Y_train,\n",
    "              batch_size=batch_size,\n",
    "              nb_epoch=10)\n",
    "    print(\"model Fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yAGKhKeRtYkS"
   },
   "outputs": [],
   "source": [
    "def trainData():\n",
    "    load_data_set()\n",
    "    a = numpy.asarray(y_train)\n",
    "    y_train_new = a.reshape(a.shape[0], 1)\n",
    "    X_train = numpy.asarray(x_train).astype('float32')\n",
    "    X_train = X_train / 255.0\n",
    "    Y_train = np_utils.to_categorical(y_train_new, nb_classes)\n",
    "    model = make_network(numpy.asarray(x_train))\n",
    "    train_model(model,X_train,Y_train)\n",
    "    \n",
    "    print(\"Model Built\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "_RH2fWUxtlAI",
    "outputId": "9d21e22b-b6f8-44b0-aebb-872d20e7f345"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asl_dataset\n",
      "[]\n",
      "['hand2_u_right_seg_2_cropped.jpeg', 'hand3_u_dif_seg_1_cropped.jpeg', 'hand1_u_bot_seg_3_cropped.jpeg', 'hand2_u_right_seg_5_cropped.jpeg', 'hand2_u_dif_seg_5_cropped.jpeg', 'hand4_u_bot_seg_1_cropped.jpeg', 'hand4_u_bot_seg_5_cropped.jpeg', 'hand5_u_dif_seg_2_cropped.jpeg', 'hand1_u_top_seg_2_cropped.jpeg', 'hand2_u_bot_seg_4_cropped.jpeg', 'hand2_u_bot_seg_5_cropped.jpeg', 'hand1_u_dif_seg_4_cropped.jpeg', 'hand1_u_dif_seg_3_cropped.jpeg', 'hand1_u_left_seg_5_cropped.jpeg', 'hand2_u_top_seg_4_cropped.jpeg', 'hand4_u_bot_seg_3_cropped.jpeg', 'hand1_u_bot_seg_5_cropped.jpeg', 'hand1_u_left_seg_1_cropped.jpeg', 'hand1_u_dif_seg_5_cropped.jpeg', 'hand3_u_dif_seg_3_cropped.jpeg', 'hand1_u_right_seg_3_cropped.jpeg', 'hand5_u_dif_seg_1_cropped.jpeg', 'hand1_u_top_seg_4_cropped.jpeg', 'hand5_u_bot_seg_5_cropped.jpeg', 'hand3_u_dif_seg_4_cropped.jpeg', 'hand2_u_left_seg_2_cropped.jpeg', 'hand1_u_right_seg_4_cropped.jpeg', 'hand2_u_bot_seg_3_cropped.jpeg', 'hand2_u_right_seg_3_cropped.jpeg', 'hand2_u_left_seg_1_cropped.jpeg', 'hand2_u_right_seg_4_cropped.jpeg', 'hand1_u_bot_seg_4_cropped.jpeg', 'hand5_u_dif_seg_4_cropped.jpeg', 'hand1_u_dif_seg_1_cropped.jpeg', 'hand1_u_left_seg_4_cropped.jpeg', 'hand5_u_bot_seg_3_cropped.jpeg', 'hand1_u_right_seg_5_cropped.jpeg', 'hand5_u_bot_seg_1_cropped.jpeg', 'hand1_u_top_seg_3_cropped.jpeg', 'hand4_u_bot_seg_4_cropped.jpeg', 'hand2_u_top_seg_2_cropped.jpeg', 'hand1_u_top_seg_1_cropped.jpeg', 'hand2_u_dif_seg_2_cropped.jpeg', 'hand2_u_left_seg_4_cropped.jpeg', 'hand1_u_right_seg_1_cropped.jpeg', 'hand2_u_bot_seg_2_cropped.jpeg', 'hand2_u_top_seg_1_cropped.jpeg', 'hand1_u_dif_seg_2_cropped.jpeg', 'hand1_u_left_seg_2_cropped.jpeg', 'hand5_u_bot_seg_2_cropped.jpeg', 'hand2_u_top_seg_3_cropped.jpeg', 'hand1_u_bot_seg_2_cropped.jpeg', 'hand2_u_dif_seg_4_cropped.jpeg', 'hand2_u_left_seg_3_cropped.jpeg', 'hand2_u_bot_seg_1_cropped.jpeg', 'hand5_u_dif_seg_3_cropped.jpeg', 'hand1_u_right_seg_2_cropped.jpeg', 'hand1_u_left_seg_3_cropped.jpeg', 'hand2_u_top_seg_5_cropped.jpeg', 'hand2_u_dif_seg_1_cropped.jpeg', 'hand3_u_dif_seg_2_cropped.jpeg', 'hand2_u_dif_seg_3_cropped.jpeg', 'hand2_u_left_seg_5_cropped.jpeg', 'hand4_u_bot_seg_2_cropped.jpeg', 'hand1_u_bot_seg_1_cropped.jpeg', 'hand3_u_dif_seg_5_cropped.jpeg', 'hand1_u_top_seg_5_cropped.jpeg', 'hand5_u_bot_seg_4_cropped.jpeg', 'hand2_u_right_seg_1_cropped.jpeg', 'hand5_u_dif_seg_5_cropped.jpeg']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "substring not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1912\\127489784.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1912\\2258184550.py\u001b[0m in \u001b[0;36mtrainData\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtrainData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mload_data_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0my_train_new\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'float32'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1912\\2476926581.py\u001b[0m in \u001b[0;36mload_data_set\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m                     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m                     \u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m                     \u001b[0mind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfullpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m                     \u001b[0ms\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfullpath\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mind\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                     \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: substring not found"
     ]
    }
   ],
   "source": [
    "model=trainData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ToRvchGQtutA"
   },
   "outputs": [],
   "source": [
    "model.save(\"/content/drive/My Drive/asl_dataset/asl2.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YV0GC_0qpPft"
   },
   "outputs": [],
   "source": [
    "# run this if model is already saved on disk.\n",
    "# model = keras.models.load_model('/content/drive/My Drive/asl_dataset/asl2.model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PwZMUJ_YGTMz"
   },
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rpdmqMutKPy3"
   },
   "outputs": [],
   "source": [
    "def prepare(filepath):\n",
    "    img_array = cv2.imread(filepath)\n",
    "    new_array = cv2.resize(img_array, (img_rows, img_cols))\n",
    "    return new_array.reshape(-1, img_rows, img_cols, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XNAneZctKgM8",
    "outputId": "89d81df2-dcf1-4035-f800-fad9c1313b74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/asl_dataset/c/hand1_c_bot_seg_1_cropped.jpeg\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict([prepare(input())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "xRndw64rK5x-",
    "outputId": "7fb83b48-729e-44d2-df0e-00f911f843e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "daUCHFDkMoLt",
    "outputId": "6a0004a5-48cf-4978-bd2d-50f72cc07542"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.argmax(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xIv8xd2cLAOj"
   },
   "outputs": [],
   "source": [
    "c=numpy.argmax(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nCex-mwDLLBk",
    "outputId": "9bffde82-f64a-4ace-a174-81bd2823a8bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C\n"
     ]
    }
   ],
   "source": [
    "for key in classes.keys():\n",
    "  if classes[key]==c:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5j7cv3GXLqi4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPEx/Xns2SEH8K5FGaPOZjY",
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "mount_file_id": "1I5Qimt-oDk7iPkUiBOs5NLVaN0Jc2dcx",
   "name": "train1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
